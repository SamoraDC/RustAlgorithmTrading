# Best Practices Research Report
**Researcher Agent - Hive Mind Swarm**
**Date:** 2025-10-21
**Task:** Research industry standards for critical trading system fixes

---

## Executive Summary

This research report provides comprehensive best practices for implementing critical fixes in the Rust algorithmic trading system. The findings cover:

1. **Stop-Loss Implementation Patterns** - Industry-proven algorithms and architectures
2. **Rust Error Handling** - Production-grade patterns using `thiserror` and `anyhow`
3. **Observability Patterns** - Real-time monitoring with Prometheus, Grafana, and DuckDB
4. **Integration Testing** - High-frequency trading testing strategies

All recommendations are tailored for the existing architecture and provide actionable implementation guidance.

---

## 1. Stop-Loss Implementation Patterns

### Current State Analysis

**File:** `/mnt/c/Users/DaviCastroSamora/Documents/SamoraDC/RustAlgorithmTrading/rust/risk-manager/src/stops.rs`

```rust
pub struct StopManager {
    config: RiskConfig,
}

impl StopManager {
    pub fn check(&self, position: &Position) {
        // TODO: Implement stop-loss checks
        // - Static stops
        // - Trailing stops
    }
}
```

**Status:** ‚ùå Not implemented - critical gap

### Industry Best Practices (2025)

#### 1.1 Stop-Loss Types

Based on research from Rust HFT frameworks and algorithmic trading systems:

**A. Fixed/Static Stops**
- **Definition:** Fixed price level or percentage from entry
- **Formula:** `stop_price = entry_price * (1 - stop_loss_percent)`
- **Use Case:** Clear risk tolerance, simple to implement
- **Pros:** Straightforward, predictable risk
- **Cons:** Can be triggered by normal volatility

**B. Trailing Stops**
- **Definition:** Adjusts automatically with favorable price movements
- **Formula:** `trailing_stop_price = max(high_price - trail_amount, previous_stop_price)`
- **Use Case:** Lock in profits while allowing upside
- **Pros:** Protects gains, follows trends
- **Cons:** More complex, requires careful tuning

**C. ATR-Based Stops**
- **Definition:** Uses Average True Range for volatility-adjusted stops
- **Formula:** `stop_distance = ATR(14) * multiplier` (typically 2-3x)
- **Use Case:** Adapts to market volatility
- **Pros:** Market-aware, reduces whipsaws
- **Cons:** Requires historical data, more computation

**D. Time-Based Stops**
- **Definition:** Exit after maximum holding period
- **Use Case:** Prevent dead capital, risk management
- **Pros:** Forces discipline, prevents indefinite holds
- **Cons:** May exit profitable positions prematurely

#### 1.2 Recommended Implementation Architecture

```rust
// /rust/risk-manager/src/stops.rs
use common::{config::RiskConfig, types::{Position, MarketData}};
use std::collections::HashMap;
use chrono::{DateTime, Utc, Duration};

/// Stop-loss types supported by the system
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum StopType {
    /// Fixed percentage or price level
    Static { stop_price: f64 },

    /// Adjusts with favorable price movements
    Trailing { trail_percent: f64, high_water_mark: f64 },

    /// Volatility-adjusted using ATR
    AtrBased { atr_multiplier: f64, current_atr: f64 },

    /// Maximum holding period
    TimeBased { max_duration: Duration, entry_time: DateTime<Utc> },
}

/// Stop-loss manager with multiple strategy support
pub struct StopManager {
    config: RiskConfig,
    /// Track stop prices per position
    active_stops: HashMap<String, StopType>,
    /// ATR calculator for volatility-based stops
    atr_calculator: AtrCalculator,
}

impl StopManager {
    pub fn new(config: RiskConfig) -> Self {
        Self {
            config,
            active_stops: HashMap::new(),
            atr_calculator: AtrCalculator::new(14), // 14-period ATR
        }
    }

    /// Check if any stops are triggered for a position
    pub fn check_stops(
        &mut self,
        position: &Position,
        current_price: f64,
        market_data: &MarketData,
    ) -> Result<bool, StopError> {
        let stop = self.active_stops
            .get(&position.symbol)
            .ok_or(StopError::NoStopFound(position.symbol.clone()))?;

        match stop {
            StopType::Static { stop_price } => {
                self.check_static_stop(position, current_price, *stop_price)
            },
            StopType::Trailing { trail_percent, high_water_mark } => {
                self.check_trailing_stop(position, current_price, *trail_percent, *high_water_mark)
            },
            StopType::AtrBased { atr_multiplier, current_atr } => {
                self.check_atr_stop(position, current_price, *atr_multiplier, *current_atr)
            },
            StopType::TimeBased { max_duration, entry_time } => {
                self.check_time_stop(*entry_time, *max_duration)
            },
        }
    }

    /// Create static stop-loss
    pub fn set_static_stop(&mut self, symbol: String, entry_price: f64, stop_percent: f64) {
        let stop_price = entry_price * (1.0 - stop_percent);
        self.active_stops.insert(symbol, StopType::Static { stop_price });
    }

    /// Create trailing stop-loss
    pub fn set_trailing_stop(&mut self, symbol: String, current_price: f64, trail_percent: f64) {
        self.active_stops.insert(
            symbol,
            StopType::Trailing {
                trail_percent,
                high_water_mark: current_price,
            },
        );
    }

    /// Update trailing stop high-water mark
    pub fn update_trailing_stop(&mut self, symbol: &str, new_high: f64) -> Result<(), StopError> {
        if let Some(stop) = self.active_stops.get_mut(symbol) {
            if let StopType::Trailing { trail_percent, high_water_mark } = stop {
                if new_high > *high_water_mark {
                    *high_water_mark = new_high;
                }
            }
        }
        Ok(())
    }

    fn check_static_stop(&self, position: &Position, current_price: f64, stop_price: f64) -> Result<bool, StopError> {
        // Long position: trigger if price falls below stop
        // Short position: trigger if price rises above stop
        let triggered = match position.side {
            PositionSide::Long => current_price <= stop_price,
            PositionSide::Short => current_price >= stop_price,
        };
        Ok(triggered)
    }

    fn check_trailing_stop(
        &self,
        position: &Position,
        current_price: f64,
        trail_percent: f64,
        high_water_mark: f64,
    ) -> Result<bool, StopError> {
        let trailing_stop_price = high_water_mark * (1.0 - trail_percent);

        let triggered = match position.side {
            PositionSide::Long => current_price <= trailing_stop_price,
            PositionSide::Short => {
                // For shorts, use low-water mark instead
                let low_water_mark = high_water_mark;
                let trailing_stop_price = low_water_mark * (1.0 + trail_percent);
                current_price >= trailing_stop_price
            },
        };
        Ok(triggered)
    }

    fn check_atr_stop(
        &self,
        position: &Position,
        current_price: f64,
        atr_multiplier: f64,
        current_atr: f64,
    ) -> Result<bool, StopError> {
        let stop_distance = current_atr * atr_multiplier;
        let stop_price = match position.side {
            PositionSide::Long => position.average_price - stop_distance,
            PositionSide::Short => position.average_price + stop_distance,
        };

        self.check_static_stop(position, current_price, stop_price)
    }

    fn check_time_stop(&self, entry_time: DateTime<Utc>, max_duration: Duration) -> Result<bool, StopError> {
        let now = Utc::now();
        let elapsed = now - entry_time;
        Ok(elapsed >= max_duration)
    }
}

/// ATR calculator for volatility measurement
pub struct AtrCalculator {
    period: usize,
    true_ranges: Vec<f64>,
}

impl AtrCalculator {
    pub fn new(period: usize) -> Self {
        Self {
            period,
            true_ranges: Vec::with_capacity(period),
        }
    }

    pub fn update(&mut self, high: f64, low: f64, prev_close: f64) -> f64 {
        let true_range = (high - low)
            .max((high - prev_close).abs())
            .max((low - prev_close).abs());

        self.true_ranges.push(true_range);
        if self.true_ranges.len() > self.period {
            self.true_ranges.remove(0);
        }

        self.calculate_atr()
    }

    fn calculate_atr(&self) -> f64 {
        if self.true_ranges.is_empty() {
            return 0.0;
        }
        self.true_ranges.iter().sum::<f64>() / self.true_ranges.len() as f64
    }
}

#[derive(Debug, thiserror::Error)]
pub enum StopError {
    #[error("No stop found for symbol: {0}")]
    NoStopFound(String),

    #[error("Invalid stop configuration: {0}")]
    InvalidConfig(String),
}
```

#### 1.3 Configuration

```toml
# /rust/risk-manager/risk-manager.toml
[stop_loss]
# Default stop-loss percentage
default_stop_percent = 2.0

# Trailing stop configuration
trailing_stop_enabled = true
trailing_stop_percent = 1.5

# ATR-based stops
atr_enabled = true
atr_period = 14
atr_multiplier = 2.5

# Time-based stops
max_holding_hours = 24

# Stop-loss enforcement
enforce_stops = true
stop_check_interval_ms = 100
```

#### 1.4 Testing Strategy

```rust
// /tests/unit/test_stop_manager.rs
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_static_stop_triggers_on_price_drop() {
        let mut manager = StopManager::new(RiskConfig::default());
        manager.set_static_stop("AAPL".to_string(), 100.0, 0.02);

        let position = Position {
            symbol: "AAPL".to_string(),
            side: PositionSide::Long,
            average_price: 100.0,
            quantity: 100,
        };

        // Should trigger at 98.0 (2% below entry)
        let triggered = manager.check_stops(&position, 97.5, &MarketData::default()).unwrap();
        assert!(triggered);
    }

    #[test]
    fn test_trailing_stop_adjusts_with_profit() {
        let mut manager = StopManager::new(RiskConfig::default());
        manager.set_trailing_stop("TSLA".to_string(), 200.0, 0.01);

        // Price rises to 210, stop should adjust
        manager.update_trailing_stop("TSLA", 210.0).unwrap();

        let position = Position {
            symbol: "TSLA".to_string(),
            side: PositionSide::Long,
            average_price: 200.0,
            quantity: 50,
        };

        // Trailing stop at 210 * 0.99 = 207.9
        let triggered = manager.check_stops(&position, 207.5, &MarketData::default()).unwrap();
        assert!(triggered);
    }

    #[test]
    fn test_atr_stop_adapts_to_volatility() {
        let mut manager = StopManager::new(RiskConfig::default());
        let atr = 5.0; // High volatility

        let position = Position {
            symbol: "NVDA".to_string(),
            side: PositionSide::Long,
            average_price: 500.0,
            quantity: 20,
        };

        // ATR stop: 500 - (5.0 * 2.5) = 487.5
        // Should NOT trigger at 490
        let triggered = manager.check_atr_stop(&position, 490.0, 2.5, atr).unwrap();
        assert!(!triggered);

        // Should trigger at 485
        let triggered = manager.check_atr_stop(&position, 485.0, 2.5, atr).unwrap();
        assert!(triggered);
    }
}
```

---

## 2. Rust Error Handling Best Practices

### Current State Analysis

**File:** `/mnt/c/Users/DaviCastroSamora/Documents/SamoraDC/RustAlgorithmTrading/rust/common/src/errors.rs`

```rust
#[derive(Error, Debug)]
pub enum TradingError {
    #[error("Market data error: {0}")]
    MarketData(String),
    // ... multiple variants
    #[error("Serialization error: {0}")]
    Serialization(#[from] serde_json::Error),
}
```

**Status:** ‚úÖ Good foundation with `thiserror`, needs enhancement

### Industry Best Practices (2025)

#### 2.1 When to Use `thiserror` vs `anyhow`

**Research Consensus:**
- **`thiserror`**: For libraries and when callers need to match on error variants
- **`anyhow`**: For applications where errors are primarily for reporting

**Recommendation for this project:**
- **Libraries** (`common`, `database`): Use `thiserror` for structured errors
- **Binaries** (`market-data`, `execution-engine`, etc.): Use `anyhow` for context

#### 2.2 Enhanced Error Architecture

```rust
// /rust/common/src/errors.rs
use thiserror::Error;

/// Main error type for trading operations
#[derive(Error, Debug)]
pub enum TradingError {
    // Market data errors with context
    #[error("Market data error for {symbol}: {source}")]
    MarketData {
        symbol: String,
        #[source]
        source: MarketDataError,
    },

    // Order validation with details
    #[error("Order validation failed: {reason}")]
    OrderValidation {
        reason: String,
        order_id: Option<String>,
    },

    // Risk check with specific failure
    #[error("Risk check failed: {check_type}")]
    RiskCheck {
        check_type: RiskCheckType,
        details: String,
    },

    // Execution errors with retry info
    #[error("Execution error: {message} (retries: {retries})")]
    Execution {
        message: String,
        retries: u32,
        is_retryable: bool,
    },

    // Network errors with retry strategy
    #[error("Network error: {0}")]
    Network(#[from] NetworkError),

    // Database errors
    #[error("Database error: {0}")]
    Database(#[from] DatabaseError),

    // Configuration errors (non-recoverable)
    #[error("Configuration error: {0}")]
    Configuration(String),

    // From external crates
    #[error("Serialization error")]
    Serialization(#[from] serde_json::Error),

    #[error("I/O error")]
    Io(#[from] std::io::Error),
}

/// Specific market data error types
#[derive(Error, Debug)]
pub enum MarketDataError {
    #[error("WebSocket connection failed: {0}")]
    WebSocketFailed(String),

    #[error("Invalid tick data: {field}")]
    InvalidTick { field: String },

    #[error("Order book desync detected")]
    OrderBookDesync,

    #[error("Data feed timeout after {duration_secs}s")]
    FeedTimeout { duration_secs: u64 },
}

/// Risk check failure types
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum RiskCheckType {
    PositionLimit,
    DrawdownLimit,
    ExposureLimit,
    StopLoss,
    CircuitBreaker,
}

impl std::fmt::Display for RiskCheckType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            RiskCheckType::PositionLimit => write!(f, "Position limit exceeded"),
            RiskCheckType::DrawdownLimit => write!(f, "Drawdown limit exceeded"),
            RiskCheckType::ExposureLimit => write!(f, "Exposure limit exceeded"),
            RiskCheckType::StopLoss => write!(f, "Stop-loss triggered"),
            RiskCheckType::CircuitBreaker => write!(f, "Circuit breaker activated"),
        }
    }
}

/// Network-specific errors
#[derive(Error, Debug)]
pub enum NetworkError {
    #[error("Connection timeout after {timeout_ms}ms")]
    Timeout { timeout_ms: u64 },

    #[error("Connection refused: {address}")]
    ConnectionRefused { address: String },

    #[error("DNS resolution failed for {host}")]
    DnsFailure { host: String },

    #[error("TLS handshake failed")]
    TlsError,
}

/// Database-specific errors
#[derive(Error, Debug)]
pub enum DatabaseError {
    #[error("Query failed: {query}")]
    QueryFailed { query: String },

    #[error("Connection pool exhausted")]
    PoolExhausted,

    #[error("Transaction deadlock")]
    Deadlock,

    #[error("Constraint violation: {constraint}")]
    ConstraintViolation { constraint: String },
}

/// Extension trait for adding context to errors
pub trait ErrorContext<T> {
    fn context(self, msg: impl Into<String>) -> Result<T>;
    fn with_context<F>(self, f: F) -> Result<T>
    where
        F: FnOnce() -> String;
}

impl<T, E> ErrorContext<T> for Result<T, E>
where
    E: Into<TradingError>,
{
    fn context(self, msg: impl Into<String>) -> Result<T> {
        self.map_err(|e| {
            let error: TradingError = e.into();
            // Log with context
            tracing::error!("Error context: {} - {:?}", msg.into(), error);
            error
        })
    }

    fn with_context<F>(self, f: F) -> Result<T>
    where
        F: FnOnce() -> String,
    {
        self.map_err(|e| {
            let error: TradingError = e.into();
            tracing::error!("Error context: {} - {:?}", f(), error);
            error
        })
    }
}

/// Result type alias for convenience
pub type Result<T> = std::result::Result<T, TradingError>;
```

#### 2.3 Application-Level Error Handling (with `anyhow`)

```rust
// /rust/execution-engine/src/main.rs
use anyhow::{Context, Result};
use tracing::{error, warn, info};

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize tracing for error tracking
    init_tracing()?;

    // Load configuration with context
    let config = load_config()
        .context("Failed to load configuration from /config/execution.toml")?;

    // Connect to exchange with retry context
    let client = connect_exchange(&config)
        .await
        .context("Failed to connect to exchange after 3 retries")?;

    // Run main loop with error reporting
    if let Err(e) = run_execution_loop(client).await {
        error!("Execution loop failed: {:?}", e);

        // Log full error chain
        for cause in e.chain() {
            error!("  caused by: {}", cause);
        }

        return Err(e);
    }

    Ok(())
}

async fn process_order(order: Order) -> Result<Trade> {
    // Validate order
    validate_order(&order)
        .with_context(|| format!("Order validation failed for order_id={}", order.id))?;

    // Check risk
    check_risk(&order)
        .with_context(|| format!("Risk check failed for {}", order.symbol))?;

    // Submit to exchange
    let trade = submit_order(&order)
        .await
        .with_context(|| format!("Failed to submit order {} to exchange", order.id))?;

    info!("Order {} executed successfully", order.id);
    Ok(trade)
}
```

#### 2.4 Error Recovery Patterns

```rust
// /rust/execution-engine/src/retry.rs
use backoff::{ExponentialBackoff, backoff::Backoff};
use std::time::Duration;

/// Retry configuration for different error types
pub struct RetryPolicy {
    max_retries: u32,
    initial_delay: Duration,
    max_delay: Duration,
    multiplier: f64,
}

impl RetryPolicy {
    /// Aggressive retry for transient network errors
    pub fn network() -> Self {
        Self {
            max_retries: 5,
            initial_delay: Duration::from_millis(100),
            max_delay: Duration::from_secs(5),
            multiplier: 2.0,
        }
    }

    /// Conservative retry for API rate limits
    pub fn rate_limit() -> Self {
        Self {
            max_retries: 3,
            initial_delay: Duration::from_secs(1),
            max_delay: Duration::from_secs(60),
            multiplier: 3.0,
        }
    }

    /// No retry for business logic errors
    pub fn none() -> Self {
        Self {
            max_retries: 0,
            initial_delay: Duration::from_secs(0),
            max_delay: Duration::from_secs(0),
            multiplier: 1.0,
        }
    }
}

/// Retry a fallible operation with exponential backoff
pub async fn retry_with_backoff<F, T, E>(
    mut operation: F,
    policy: RetryPolicy,
) -> Result<T, E>
where
    F: FnMut() -> Result<T, E>,
    E: std::fmt::Debug,
{
    let mut backoff = ExponentialBackoff {
        initial_interval: policy.initial_delay,
        max_interval: policy.max_delay,
        multiplier: policy.multiplier,
        max_elapsed_time: Some(policy.max_delay * policy.max_retries),
        ..Default::default()
    };

    let mut attempts = 0;
    loop {
        match operation() {
            Ok(result) => return Ok(result),
            Err(err) if attempts >= policy.max_retries => {
                error!("Operation failed after {} attempts: {:?}", attempts, err);
                return Err(err);
            }
            Err(err) => {
                attempts += 1;
                let delay = backoff.next_backoff()
                    .unwrap_or(policy.max_delay);

                warn!("Attempt {} failed, retrying in {:?}: {:?}", attempts, delay, err);
                tokio::time::sleep(delay).await;
            }
        }
    }
}
```

#### 2.5 Recommended Dependencies

```toml
# /rust/Cargo.toml
[workspace.dependencies]
# Error handling
thiserror = "2.0"      # For library error types
anyhow = "2.0"         # For application error handling

# Logging and tracing
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }
tracing-error = "0.3"  # For error span traces

# Retry and backoff
backoff = "0.4"
tokio-retry = "0.3"

# Error reporting (optional, for production)
sentry = "0.32"        # Error tracking service
```

---

## 3. Observability Patterns for Real-Time Trading

### Current State Analysis

**Files:**
- `/src/observability/metrics/collectors.py` - Basic collector framework
- `/src/observability/api/main.py` - FastAPI observability API
- DuckDB integration for analytics

**Status:** ‚úÖ Good foundation, needs performance optimization

### Industry Best Practices (2025)

#### 3.1 Observability Stack Architecture

**Recommended Tools:**
1. **Prometheus** - Metrics collection and alerting (71% adoption in 2025)
2. **Grafana** - Visualization and dashboards
3. **DuckDB** - High-performance analytical queries
4. **Loki** - Log aggregation (optional)
5. **OpenTelemetry** - Distributed tracing

**Integration Pattern:**
```
Rust Services ‚Üí Prometheus Metrics Exporter
              ‚Üì
         Prometheus Server
              ‚Üì
         Grafana Dashboards

Rust Services ‚Üí DuckDB Analytics
              ‚Üì
         Observability API
              ‚Üì
         Custom Dashboards
```

#### 3.2 Prometheus Integration for Rust

```rust
// /rust/common/src/metrics.rs
use metrics::{counter, gauge, histogram, describe_counter, describe_gauge, describe_histogram};
use metrics_exporter_prometheus::PrometheusBuilder;
use std::time::Instant;

/// Initialize Prometheus metrics exporter
pub fn init_metrics(port: u16) -> anyhow::Result<()> {
    PrometheusBuilder::new()
        .with_http_listener(([0, 0, 0, 0], port))
        .install()?;

    // Describe metrics for documentation
    describe_counter!("orders_submitted_total", "Total number of orders submitted");
    describe_counter!("orders_filled_total", "Total number of orders filled");
    describe_counter!("orders_rejected_total", "Total number of orders rejected");

    describe_gauge!("active_positions", "Number of active positions");
    describe_gauge!("total_exposure_usd", "Total market exposure in USD");
    describe_gauge!("unrealized_pnl_usd", "Unrealized P&L in USD");

    describe_histogram!("order_latency_ms", "Order submission latency in milliseconds");
    describe_histogram!("tick_processing_us", "Tick processing time in microseconds");
    describe_histogram!("orderbook_update_us", "Order book update time in microseconds");

    Ok(())
}

/// Metrics collector for trading operations
pub struct TradingMetrics;

impl TradingMetrics {
    /// Record order submission
    pub fn order_submitted(symbol: &str, side: &str) {
        counter!("orders_submitted_total", "symbol" => symbol.to_string(), "side" => side.to_string()).increment(1);
    }

    /// Record order fill
    pub fn order_filled(symbol: &str, quantity: u64, price: f64) {
        counter!("orders_filled_total", "symbol" => symbol.to_string()).increment(1);
        gauge!("last_fill_price", "symbol" => symbol.to_string()).set(price);
        gauge!("last_fill_quantity", "symbol" => symbol.to_string()).set(quantity as f64);
    }

    /// Record order rejection
    pub fn order_rejected(symbol: &str, reason: &str) {
        counter!("orders_rejected_total", "symbol" => symbol.to_string(), "reason" => reason.to_string()).increment(1);
    }

    /// Update position metrics
    pub fn update_positions(count: u64, exposure_usd: f64, pnl_usd: f64) {
        gauge!("active_positions").set(count as f64);
        gauge!("total_exposure_usd").set(exposure_usd);
        gauge!("unrealized_pnl_usd").set(pnl_usd);
    }

    /// Record order latency
    pub fn record_latency(operation: &str, start: Instant) {
        let duration = start.elapsed().as_millis() as f64;
        histogram!("order_latency_ms", "operation" => operation.to_string()).record(duration);
    }

    /// Record tick processing performance
    pub fn tick_processed(symbol: &str, processing_time_us: f64) {
        histogram!("tick_processing_us", "symbol" => symbol.to_string()).record(processing_time_us);
        counter!("ticks_processed_total", "symbol" => symbol.to_string()).increment(1);
    }

    /// Record orderbook update performance
    pub fn orderbook_updated(symbol: &str, update_time_us: f64) {
        histogram!("orderbook_update_us", "symbol" => symbol.to_string()).record(update_time_us);
    }

    /// Record risk check decision
    pub fn risk_check(passed: bool, check_type: &str) {
        let status = if passed { "passed" } else { "failed" };
        counter!("risk_checks_total", "type" => check_type.to_string(), "status" => status.to_string()).increment(1);
    }
}
```

#### 3.3 DuckDB Optimization (from Bottleneck Analysis)

**Critical Optimizations:**

1. **Batched Write Queue** (5x throughput improvement)
2. **Connection Pooling** (75% memory reduction)
3. **Streaming Queries** (prevents OOM on large datasets)
4. **Rate Limiting** (prevents DoS)
5. **Concurrent WebSocket Broadcast** (100x latency improvement)

**Implementation:** See `/docs/analysis/BOTTLENECK_ANALYSIS.md` for detailed solutions.

#### 3.4 Grafana Dashboard Configuration

```yaml
# /config/grafana/trading_dashboard.json
{
  "dashboard": {
    "title": "Algorithmic Trading System",
    "panels": [
      {
        "title": "Order Flow",
        "targets": [
          {
            "expr": "rate(orders_submitted_total[1m])",
            "legendFormat": "Submitted"
          },
          {
            "expr": "rate(orders_filled_total[1m])",
            "legendFormat": "Filled"
          },
          {
            "expr": "rate(orders_rejected_total[1m])",
            "legendFormat": "Rejected"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Order Latency (p50, p95, p99)",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(order_latency_ms_bucket[5m]))",
            "legendFormat": "p50"
          },
          {
            "expr": "histogram_quantile(0.95, rate(order_latency_ms_bucket[5m]))",
            "legendFormat": "p95"
          },
          {
            "expr": "histogram_quantile(0.99, rate(order_latency_ms_bucket[5m]))",
            "legendFormat": "p99"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Active Positions & Exposure",
        "targets": [
          {
            "expr": "active_positions",
            "legendFormat": "Positions"
          },
          {
            "expr": "total_exposure_usd",
            "legendFormat": "Exposure (USD)"
          }
        ],
        "type": "stat"
      },
      {
        "title": "Unrealized P&L",
        "targets": [
          {
            "expr": "unrealized_pnl_usd",
            "legendFormat": "P&L (USD)"
          }
        ],
        "type": "gauge"
      },
      {
        "title": "Risk Checks",
        "targets": [
          {
            "expr": "rate(risk_checks_total{status=\"failed\"}[5m])",
            "legendFormat": "{{type}}"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

#### 3.5 Alerting Rules

```yaml
# /config/prometheus/alerts.yml
groups:
  - name: trading_alerts
    interval: 10s
    rules:
      # High order rejection rate
      - alert: HighOrderRejectionRate
        expr: rate(orders_rejected_total[1m]) > 10
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High order rejection rate detected"
          description: "Order rejection rate is {{ $value }} orders/sec"

      # Order latency exceeds threshold
      - alert: HighOrderLatency
        expr: histogram_quantile(0.99, rate(order_latency_ms_bucket[5m])) > 1000
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Order latency p99 > 1 second"
          description: "p99 latency is {{ $value }}ms"

      # Position exposure exceeds limit
      - alert: ExposureLimitExceeded
        expr: total_exposure_usd > 100000
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Total exposure exceeds $100k limit"
          description: "Current exposure: ${{ $value }}"

      # Drawdown alert
      - alert: DrawdownAlert
        expr: unrealized_pnl_usd < -5000
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Drawdown exceeds $5k"
          description: "Unrealized P&L: ${{ $value }}"

      # Tick processing lag
      - alert: TickProcessingLag
        expr: rate(ticks_processed_total[1m]) < 100
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Tick processing rate below 100/sec"
          description: "Current rate: {{ $value }} ticks/sec"
```

---

## 4. Integration Testing Best Practices

### Current State Analysis

**Files:**
- `/tests/integration/test_end_to_end.rs` - Basic E2E tests
- `/tests/integration/test_duckdb_storage.rs` - Database integration
- `/docs/testing/TEST_STRATEGY.md` - Comprehensive test strategy

**Status:** ‚úÖ Good framework, needs HFT-specific patterns

### Industry Best Practices (2025)

#### 4.1 HFT Testing Architecture

**Key Principles:**
1. **Realistic Data Volume** - Simulate actual tick rates (1000s/sec)
2. **Latency Simulation** - Network delays, exchange latency
3. **Market Condition Scenarios** - Normal, volatile, crash scenarios
4. **Performance Validation** - Sub-millisecond requirements
5. **Hardware-in-the-Loop** - Test on production-like hardware

#### 4.2 Market Data Simulator

```rust
// /tests/fixtures/market_simulator.rs
use std::time::{Duration, Instant};
use tokio::sync::mpsc;
use rand::Rng;

/// Simulates realistic market data feeds
pub struct MarketDataSimulator {
    tick_rate_hz: u32,
    volatility: f64,
    symbols: Vec<String>,
}

impl MarketDataSimulator {
    pub fn new(tick_rate_hz: u32, volatility: f64, symbols: Vec<String>) -> Self {
        Self {
            tick_rate_hz,
            volatility,
            symbols,
        }
    }

    /// Generate realistic tick stream with specified characteristics
    pub async fn generate_ticks(
        &self,
        duration: Duration,
        tx: mpsc::Sender<MarketTick>,
    ) -> anyhow::Result<usize> {
        let mut rng = rand::thread_rng();
        let interval = Duration::from_micros(1_000_000 / self.tick_rate_hz as u64);
        let start = Instant::now();
        let mut tick_count = 0;

        while start.elapsed() < duration {
            for symbol in &self.symbols {
                // Generate realistic price movement (Geometric Brownian Motion)
                let price_change = rng.gen_range(-self.volatility..self.volatility);
                let base_price = 100.0; // Base price
                let price = base_price * (1.0 + price_change);

                // Generate bid-ask spread (0.01% - 0.05%)
                let spread_pct = rng.gen_range(0.0001..0.0005);
                let spread = price * spread_pct;

                let tick = MarketTick {
                    symbol: symbol.clone(),
                    timestamp: Utc::now(),
                    bid: price - spread / 2.0,
                    ask: price + spread / 2.0,
                    bid_size: rng.gen_range(100..10000),
                    ask_size: rng.gen_range(100..10000),
                    last_trade_price: Some(price),
                    last_trade_size: Some(rng.gen_range(1..1000)),
                };

                tx.send(tick).await?;
                tick_count += 1;
            }

            tokio::time::sleep(interval).await;
        }

        Ok(tick_count)
    }

    /// Simulate market conditions (crash, rally, consolidation)
    pub async fn simulate_scenario(
        &self,
        scenario: MarketScenario,
        tx: mpsc::Sender<MarketTick>,
    ) -> anyhow::Result<()> {
        match scenario {
            MarketScenario::Flash Crash => self.simulate_crash(tx).await,
            MarketScenario::Rally => self.simulate_rally(tx).await,
            MarketScenario::Consolidation => self.simulate_consolidation(tx).await,
        }
    }

    async fn simulate_crash(&self, tx: mpsc::Sender<MarketTick>) -> anyhow::Result<()> {
        // 10% drop in 1 second
        let drop_percent = 0.10;
        let duration = Duration::from_secs(1);
        let ticks = (self.tick_rate_hz as f64 * duration.as_secs_f64()) as usize;

        for i in 0..ticks {
            let price_factor = 1.0 - (drop_percent * (i as f64 / ticks as f64));
            // ... generate ticks with declining prices
        }
        Ok(())
    }
}

#[derive(Debug, Clone)]
pub enum MarketScenario {
    FlashCrash,
    Rally,
    Consolidation,
}
```

#### 4.3 Performance Integration Tests

```rust
// /tests/integration/test_performance.rs
use criterion::black_box;
use std::time::Instant;

#[tokio::test]
async fn test_order_submission_latency() {
    // Setup
    let engine = ExecutionEngine::new(config).await.unwrap();
    let order = create_test_order("AAPL", 100, 150.0);

    // Warm-up
    for _ in 0..100 {
        let _ = engine.validate_order(&order);
    }

    // Measure latency
    let iterations = 10000;
    let start = Instant::now();

    for _ in 0..iterations {
        black_box(engine.validate_order(&order).unwrap());
    }

    let elapsed = start.elapsed();
    let avg_latency_ns = elapsed.as_nanos() / iterations;

    // Assert sub-microsecond latency
    assert!(avg_latency_ns < 1000, "Order validation latency {}ns exceeds 1Œºs", avg_latency_ns);

    println!("Average order validation latency: {}ns", avg_latency_ns);
}

#[tokio::test]
async fn test_tick_processing_throughput() {
    let processor = TickProcessor::new();
    let (tx, mut rx) = mpsc::channel(10000);

    // Generate 100k ticks
    let simulator = MarketDataSimulator::new(10000, 0.01, vec!["AAPL".to_string()]);

    let start = Instant::now();

    tokio::spawn(async move {
        simulator.generate_ticks(Duration::from_secs(10), tx).await.unwrap();
    });

    let mut processed = 0;
    while let Some(tick) = rx.recv().await {
        processor.process(tick).await.unwrap();
        processed += 1;
    }

    let elapsed = start.elapsed();
    let throughput = processed as f64 / elapsed.as_secs_f64();

    // Assert > 100k ticks/sec throughput
    assert!(throughput > 100_000.0, "Tick processing throughput {} ticks/sec is below requirement", throughput);

    println!("Tick processing throughput: {:.0} ticks/sec", throughput);
}
```

#### 4.4 Chaos Engineering Tests

```rust
// /tests/integration/test_chaos.rs
use tokio::time::{sleep, Duration};
use rand::Rng;

#[tokio::test]
async fn test_network_partition_recovery() {
    let mut system = TradingSystem::new(config).await.unwrap();

    // Start normal operation
    system.start().await.unwrap();
    sleep(Duration::from_secs(5)).await;

    // Simulate network partition
    system.simulate_network_partition(Duration::from_secs(10)).await;

    // Verify graceful degradation
    assert!(system.is_in_degraded_mode());
    assert_eq!(system.pending_orders_count(), 0, "Orders should not be submitted during partition");

    // Restore network
    system.restore_network().await;
    sleep(Duration::from_secs(2)).await;

    // Verify recovery
    assert!(system.is_healthy());
    assert!(system.can_submit_orders());
}

#[tokio::test]
async fn test_exchange_api_failure_handling() {
    let mut system = TradingSystem::new(config).await.unwrap();

    // Inject random API failures (10% failure rate)
    system.set_api_failure_rate(0.10);

    // Submit 1000 orders
    let mut successful = 0;
    let mut retried = 0;

    for i in 0..1000 {
        let order = create_test_order(&format!("AAPL-{}", i), 10, 150.0);

        match system.submit_order(order).await {
            Ok(_) => successful += 1,
            Err(e) if e.is_retryable() => {
                retried += 1;
                // Retry logic should handle this
            },
            Err(e) => panic!("Unexpected non-retryable error: {:?}", e),
        }
    }

    // Verify retry mechanism worked
    assert!(successful > 850, "Success rate {} is too low", successful);
    println!("Successful: {}, Retried: {}", successful, retried);
}

#[tokio::test]
async fn test_data_feed_lag_handling() {
    let mut system = TradingSystem::new(config).await.unwrap();

    // Simulate data feed lag (500ms delay)
    system.simulate_data_lag(Duration::from_millis(500)).await;

    // Verify system detects stale data
    sleep(Duration::from_secs(1)).await;
    assert!(system.is_data_stale(), "System should detect stale market data");

    // Verify trading halted due to stale data
    let order = create_test_order("AAPL", 100, 150.0);
    assert!(system.submit_order(order).await.is_err(), "Should reject orders with stale data");

    // Restore normal data feed
    system.restore_data_feed().await;
    sleep(Duration::from_secs(1)).await;
    assert!(!system.is_data_stale());
}
```

#### 4.5 Property-Based Testing for Financial Invariants

```rust
// /tests/property/test_financial_invariants.rs
use proptest::prelude::*;

proptest! {
    // P&L calculation must be consistent
    #[test]
    fn test_pnl_calculation_invariant(
        entry_price in 1.0f64..1000.0,
        exit_price in 1.0f64..1000.0,
        quantity in 1i32..10000,
    ) {
        let position = Position {
            average_price: entry_price,
            quantity,
            current_price: exit_price,
        };

        let expected_pnl = (exit_price - entry_price) * quantity as f64;
        let calculated_pnl = position.unrealized_pnl();

        let diff = (expected_pnl - calculated_pnl).abs();
        prop_assert!(diff < 0.01, "P&L calculation mismatch: expected={}, got={}", expected_pnl, calculated_pnl);
    }

    // Position value must never be negative
    #[test]
    fn test_position_value_non_negative(
        quantity in 0i32..10000,
        price in 0.0f64..1000.0,
    ) {
        let position = Position {
            quantity,
            average_price: price,
            current_price: price,
        };

        let value = position.market_value();
        prop_assert!(value >= 0.0, "Position value cannot be negative: {}", value);
    }

    // Spread must be non-negative
    #[test]
    fn test_spread_non_negative(
        bid in 1.0f64..1000.0,
        spread_pct in 0.0001f64..0.01, // 0.01% to 1%
    ) {
        let ask = bid * (1.0 + spread_pct);
        let spread = ask - bid;

        prop_assert!(spread >= 0.0, "Spread cannot be negative");
        prop_assert!(ask >= bid, "Ask must be >= bid");
    }

    // Risk exposure cannot exceed limits
    #[test]
    fn test_exposure_limit_invariant(
        positions in prop::collection::vec(
            (1.0f64..1000.0, 1i32..1000), // (price, quantity)
            1..10 // 1-10 positions
        ),
        max_exposure in 10000.0f64..100000.0,
    ) {
        let mut total_exposure = 0.0;
        for (price, quantity) in positions {
            total_exposure += price * quantity as f64;
        }

        let risk_manager = RiskManager::new(RiskConfig {
            max_exposure_usd: max_exposure,
            ..Default::default()
        });

        if total_exposure > max_exposure {
            prop_assert!(
                !risk_manager.check_exposure(total_exposure),
                "Risk manager should reject exposure {} exceeding limit {}",
                total_exposure,
                max_exposure
            );
        }
    }
}
```

---

## 5. Actionable Recommendations Summary

### Priority 1: Stop-Loss Implementation (Week 1)

1. **Implement `StopManager` with 4 stop types:**
   - Static stops (fixed price/percentage)
   - Trailing stops (adjusts with profit)
   - ATR-based stops (volatility-adjusted)
   - Time-based stops (max holding period)

2. **Add comprehensive tests:**
   - Unit tests for each stop type
   - Integration tests with position updates
   - Property-based tests for edge cases

3. **Configuration:**
   - Add stop-loss config to `risk-manager.toml`
   - Expose stop parameters via API/CLI

**Estimated Effort:** 3-4 days
**Impact:** HIGH - Critical risk management feature

### Priority 2: Error Handling Enhancement (Week 1-2)

1. **Enhance error types:**
   - Add context to all error variants
   - Implement `ErrorContext` trait
   - Add retry metadata to errors

2. **Binary error handling:**
   - Add `anyhow` to all binaries
   - Implement proper error chain logging
   - Add sentry integration for production

3. **Retry policies:**
   - Implement exponential backoff
   - Add retry policies for different error types
   - Test retry behavior under failures

**Estimated Effort:** 2-3 days
**Impact:** MEDIUM - Improves debugging and resilience

### Priority 3: Observability Optimization (Week 2)

1. **Prometheus integration:**
   - Add `metrics-exporter-prometheus` to Rust services
   - Implement `TradingMetrics` collector
   - Expose metrics on port 9090

2. **DuckDB optimizations:**
   - Implement batched write queue
   - Add connection pooling
   - Implement streaming queries

3. **Grafana dashboards:**
   - Create trading dashboard with 5 core panels
   - Configure alerting rules
   - Test WebSocket real-time updates

**Estimated Effort:** 4-5 days
**Impact:** MEDIUM - Production readiness

### Priority 4: Integration Testing (Week 3)

1. **Market data simulator:**
   - Realistic tick generation (1000+ ticks/sec)
   - Market scenario simulation (crash, rally)
   - Latency injection for network delays

2. **Performance tests:**
   - Order submission latency (<1Œºs target)
   - Tick processing throughput (>100k ticks/sec)
   - End-to-end order lifecycle

3. **Chaos engineering:**
   - Network partition tests
   - API failure injection
   - Data feed lag simulation

**Estimated Effort:** 5-6 days
**Impact:** HIGH - Ensures production reliability

---

## 6. References and Resources

### Stop-Loss Implementation
- [Rust for HFT - Luca Sbardella](https://lucasbardella.com/coding/2025/rust-for-hft)
- [Barter-rs Framework](https://github.com/barter-rs/barter-rs)
- [LuxAlgo Risk Management Guide](https://www.luxalgo.com/blog/risk-management-strategies-for-algo-trading/)

### Error Handling
- [Rust Error Handling 2025 Guide](https://markaicode.com/rust-error-handling-2025-guide/)
- [thiserror vs anyhow Guide](https://www.shakacode.com/blog/thiserror-anyhow-or-how-i-handle-errors-in-rust-apps/)
- [GreptimeDB Error Patterns](https://greptime.com/blogs/2024-05-07-error-rust)

### Observability
- [Grafana 2025 Trends](https://grafana.com/blog/2024/12/16/2025-observability-predictions-and-trends-from-grafana-labs/)
- [DuckDB for Observability](https://neogeografia.wordpress.com/2023/08/02/observability-and-log-analytics-with-duckdb/)
- [Prometheus Complete Guide](https://upcloud.com/blog/observability-with-prometheus-complete-guide/)

### Integration Testing
- [HFT Backtesting Framework](https://github.com/nkaz001/hftbacktest)
- [Rust Fintech Platform](https://www.manning.com/liveprojectseries/fintech-platform-ser)
- [Performance Testing for HFT](https://assuredthought.com/insight/legacy-system-modernisation-in-traditional-banks-a-path-to-digital-excellence_2)

---

## 7. Next Steps

**For Coder Agent:**
1. Implement `StopManager` in `/rust/risk-manager/src/stops.rs`
2. Add `TradingMetrics` in `/rust/common/src/metrics.rs`
3. Create `MarketDataSimulator` in `/tests/fixtures/market_simulator.rs`

**For Tester Agent:**
1. Write comprehensive stop-loss unit tests
2. Create performance integration tests
3. Implement chaos engineering test suite

**For DevOps Agent:**
1. Deploy Prometheus and Grafana
2. Configure alerting rules
3. Set up DuckDB connection pooling

**For Reviewer Agent:**
1. Review error handling patterns
2. Validate observability metrics
3. Ensure test coverage >90%

---

**Prepared by:** Researcher Agent (Hive Mind Swarm)
**Status:** ‚úÖ Research Complete
**Stored in Memory:** `hive/researcher/best-practices`
